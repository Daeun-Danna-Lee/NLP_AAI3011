{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-nltk-preprocessing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMKQW+Zm4mFEC1CDe11qs4d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daeun-Danna-Lee/NLP_AAI3011/blob/main/nlp_nltk_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7hA1rn4J_Vt"
      },
      "source": [
        "# 1. 텍스트로만 이루어진 사이트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SascrAUILrn"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBYdBPJzIcGR"
      },
      "source": [
        "nltk.download('all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9ksCQH7DPVz"
      },
      "source": [
        "from urllib import request\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6pdC6_hDX55"
      },
      "source": [
        "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2ewe-2mD_V2"
      },
      "source": [
        "response = request.urlopen(url)\n",
        "raw = response.read().decode('utf8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIQxasNXEh5v",
        "outputId": "a8293e84-9f2c-4c88-e6ef-91d2ad561a38"
      },
      "source": [
        "type(raw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WyFBfBuEi0z",
        "outputId": "5f0ba061-914d-4f20-aa3a-9f9dd2e55fce"
      },
      "source": [
        "len(raw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1176812"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GvN1CE4yEj7h",
        "outputId": "52434ae8-a93c-4323-fb7b-8ffa8f18f8d5"
      },
      "source": [
        "raw[1:74]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The Project Gutenberg eBook of Crime and Punishment, by Fyodor Dostoevsky'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OspDBHTHEldg"
      },
      "source": [
        "tokens = word_tokenize(raw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUJ81UV6E7EU",
        "outputId": "2627d4a5-41de-4ddd-ee82-8efedfbcc9fe"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "257712"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyrTm9QAI8QS",
        "outputId": "0c23d333-48a7-4f21-9011-fad47af915fe"
      },
      "source": [
        "tokens[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\ufeffThe',\n",
              " 'Project',\n",
              " 'Gutenberg',\n",
              " 'eBook',\n",
              " 'of',\n",
              " 'Crime',\n",
              " 'and',\n",
              " 'Punishment',\n",
              " ',',\n",
              " 'by']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNY-aaqhI-XS"
      },
      "source": [
        "text= nltk.Text(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuIMlq22JOl2",
        "outputId": "9ff0d24d-f057-4457-ce05-4554079c00a3"
      },
      "source": [
        "text[1024:1062]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wisdom',\n",
              " '...',\n",
              " 'that',\n",
              " 'wisdom',\n",
              " 'of',\n",
              " 'the',\n",
              " 'heart',\n",
              " 'which',\n",
              " 'we',\n",
              " 'seek',\n",
              " 'that',\n",
              " 'we',\n",
              " 'may',\n",
              " 'learn',\n",
              " 'from',\n",
              " 'it',\n",
              " 'how',\n",
              " 'to',\n",
              " 'live',\n",
              " '.',\n",
              " 'All',\n",
              " 'his',\n",
              " 'other',\n",
              " 'gifts',\n",
              " 'came',\n",
              " 'to',\n",
              " 'him',\n",
              " 'from',\n",
              " 'nature',\n",
              " ',',\n",
              " 'this',\n",
              " 'he',\n",
              " 'won',\n",
              " 'for',\n",
              " 'himself',\n",
              " 'and',\n",
              " 'through',\n",
              " 'it']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7YMn8iKJQrT",
        "outputId": "334f3489-1262-4e98-ba5f-cad990055ad1"
      },
      "source": [
        "text.collocations()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
            "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
            "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
            "great deal; young man; Nikodim Fomitch; Project Gutenberg; Ilya\n",
            "Petrovitch; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
            "heavens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k24fniFcJTwk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l6vtGc_J3Rt"
      },
      "source": [
        "# 2. BeutifulSoup 활용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ14nLwzLDoM"
      },
      "source": [
        "## 1) HTML 크롤링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GgtahEQJ8LP"
      },
      "source": [
        "url_bs = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
        "html = request.urlopen(url_bs).read().decode('utf8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pbKIilrKVhl"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "raw_bs = BeautifulSoup(html, 'lxml').get_text()\n",
        "tokens_bs = word_tokenize(raw_bs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O50z12bCKh7X",
        "outputId": "81cf4f95-279a-4057-c18c-1aebd3142a09"
      },
      "source": [
        "tokens_bs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BBC',\n",
              " 'NEWS',\n",
              " '|',\n",
              " 'Health',\n",
              " '|',\n",
              " 'Blondes',\n",
              " \"'to\",\n",
              " 'die',\n",
              " 'out',\n",
              " 'in',\n",
              " '200',\n",
              " \"years'\",\n",
              " 'NEWS',\n",
              " 'SPORT',\n",
              " 'WEATHER',\n",
              " 'WORLD',\n",
              " 'SERVICE',\n",
              " 'A-Z',\n",
              " 'INDEX',\n",
              " 'SEARCH',\n",
              " 'You',\n",
              " 'are',\n",
              " 'in',\n",
              " ':',\n",
              " 'Health',\n",
              " 'News',\n",
              " 'Front',\n",
              " 'Page',\n",
              " 'Africa',\n",
              " 'Americas',\n",
              " 'Asia-Pacific',\n",
              " 'Europe',\n",
              " 'Middle',\n",
              " 'East',\n",
              " 'South',\n",
              " 'Asia',\n",
              " 'UK',\n",
              " 'Business',\n",
              " 'Entertainment',\n",
              " 'Science/Nature',\n",
              " 'Technology',\n",
              " 'Health',\n",
              " 'Medical',\n",
              " 'notes',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '-',\n",
              " 'Talking',\n",
              " 'Point',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '-',\n",
              " 'Country',\n",
              " 'Profiles',\n",
              " 'In',\n",
              " 'Depth',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '-',\n",
              " 'Programmes',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '-',\n",
              " 'SERVICES',\n",
              " 'Daily',\n",
              " 'E-mail',\n",
              " 'News',\n",
              " 'Ticker',\n",
              " 'Mobile/PDAs',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '-',\n",
              " 'Text',\n",
              " 'Only',\n",
              " 'Feedback',\n",
              " 'Help',\n",
              " 'EDITIONS',\n",
              " 'Change',\n",
              " 'to',\n",
              " 'UK',\n",
              " 'Friday',\n",
              " ',',\n",
              " '27',\n",
              " 'September',\n",
              " ',',\n",
              " '2002',\n",
              " ',',\n",
              " '11:51',\n",
              " 'GMT',\n",
              " '12:51',\n",
              " 'UK',\n",
              " 'Blondes',\n",
              " \"'to\",\n",
              " 'die',\n",
              " 'out',\n",
              " 'in',\n",
              " '200',\n",
              " \"years'\",\n",
              " 'Scientists',\n",
              " 'believe',\n",
              " 'the',\n",
              " 'last',\n",
              " 'blondes',\n",
              " 'will',\n",
              " 'be',\n",
              " 'in',\n",
              " 'Finland',\n",
              " 'The',\n",
              " 'last',\n",
              " 'natural',\n",
              " 'blondes',\n",
              " 'will',\n",
              " 'die',\n",
              " 'out',\n",
              " 'within',\n",
              " '200',\n",
              " 'years',\n",
              " ',',\n",
              " 'scientists',\n",
              " 'believe',\n",
              " '.',\n",
              " 'A',\n",
              " 'study',\n",
              " 'by',\n",
              " 'experts',\n",
              " 'in',\n",
              " 'Germany',\n",
              " 'suggests',\n",
              " 'people',\n",
              " 'with',\n",
              " 'blonde',\n",
              " 'hair',\n",
              " 'are',\n",
              " 'an',\n",
              " 'endangered',\n",
              " 'species',\n",
              " 'and',\n",
              " 'will',\n",
              " 'become',\n",
              " 'extinct',\n",
              " 'by',\n",
              " '2202',\n",
              " '.',\n",
              " 'Researchers',\n",
              " 'predict',\n",
              " 'the',\n",
              " 'last',\n",
              " 'truly',\n",
              " 'natural',\n",
              " 'blonde',\n",
              " 'will',\n",
              " 'be',\n",
              " 'born',\n",
              " 'in',\n",
              " 'Finland',\n",
              " '-',\n",
              " 'the',\n",
              " 'country',\n",
              " 'with',\n",
              " 'the',\n",
              " 'highest',\n",
              " 'proportion',\n",
              " 'of',\n",
              " 'blondes',\n",
              " '.',\n",
              " 'The',\n",
              " 'frequency',\n",
              " 'of',\n",
              " 'blondes',\n",
              " 'may',\n",
              " 'drop',\n",
              " 'but',\n",
              " 'they',\n",
              " 'wo',\n",
              " \"n't\",\n",
              " 'disappear',\n",
              " 'Prof',\n",
              " 'Jonathan',\n",
              " 'Rees',\n",
              " ',',\n",
              " 'University',\n",
              " 'of',\n",
              " 'Edinburgh',\n",
              " 'But',\n",
              " 'they',\n",
              " 'say',\n",
              " 'too',\n",
              " 'few',\n",
              " 'people',\n",
              " 'now',\n",
              " 'carry',\n",
              " 'the',\n",
              " 'gene',\n",
              " 'for',\n",
              " 'blondes',\n",
              " 'to',\n",
              " 'last',\n",
              " 'beyond',\n",
              " 'the',\n",
              " 'next',\n",
              " 'two',\n",
              " 'centuries',\n",
              " '.',\n",
              " 'The',\n",
              " 'problem',\n",
              " 'is',\n",
              " 'that',\n",
              " 'blonde',\n",
              " 'hair',\n",
              " 'is',\n",
              " 'caused',\n",
              " 'by',\n",
              " 'a',\n",
              " 'recessive',\n",
              " 'gene',\n",
              " '.',\n",
              " 'In',\n",
              " 'order',\n",
              " 'for',\n",
              " 'a',\n",
              " 'child',\n",
              " 'to',\n",
              " 'have',\n",
              " 'blonde',\n",
              " 'hair',\n",
              " ',',\n",
              " 'it',\n",
              " 'must',\n",
              " 'have',\n",
              " 'the',\n",
              " 'gene',\n",
              " 'on',\n",
              " 'both',\n",
              " 'sides',\n",
              " 'of',\n",
              " 'the',\n",
              " 'family',\n",
              " 'in',\n",
              " 'the',\n",
              " 'grandparents',\n",
              " \"'\",\n",
              " 'generation',\n",
              " '.',\n",
              " 'Dyed',\n",
              " 'rivals',\n",
              " 'The',\n",
              " 'researchers',\n",
              " 'also',\n",
              " 'believe',\n",
              " 'that',\n",
              " 'so-called',\n",
              " 'bottle',\n",
              " 'blondes',\n",
              " 'may',\n",
              " 'be',\n",
              " 'to',\n",
              " 'blame',\n",
              " 'for',\n",
              " 'the',\n",
              " 'demise',\n",
              " 'of',\n",
              " 'their',\n",
              " 'natural',\n",
              " 'rivals',\n",
              " '.',\n",
              " 'They',\n",
              " 'suggest',\n",
              " 'that',\n",
              " 'dyed-blondes',\n",
              " 'are',\n",
              " 'more',\n",
              " 'attractive',\n",
              " 'to',\n",
              " 'men',\n",
              " 'who',\n",
              " 'choose',\n",
              " 'them',\n",
              " 'as',\n",
              " 'partners',\n",
              " 'over',\n",
              " 'true',\n",
              " 'blondes',\n",
              " '.',\n",
              " 'Bottle-blondes',\n",
              " 'like',\n",
              " 'Ann',\n",
              " 'Widdecombe',\n",
              " 'may',\n",
              " 'be',\n",
              " 'to',\n",
              " 'blame',\n",
              " 'But',\n",
              " 'Jonathan',\n",
              " 'Rees',\n",
              " ',',\n",
              " 'professor',\n",
              " 'of',\n",
              " 'dermatology',\n",
              " 'at',\n",
              " 'the',\n",
              " 'University',\n",
              " 'of',\n",
              " 'Edinburgh',\n",
              " 'said',\n",
              " 'it',\n",
              " 'was',\n",
              " 'unlikely',\n",
              " 'blondes',\n",
              " 'would',\n",
              " 'die',\n",
              " 'out',\n",
              " 'completely',\n",
              " '.',\n",
              " '``',\n",
              " 'Genes',\n",
              " 'do',\n",
              " \"n't\",\n",
              " 'die',\n",
              " 'out',\n",
              " 'unless',\n",
              " 'there',\n",
              " 'is',\n",
              " 'a',\n",
              " 'disadvantage',\n",
              " 'of',\n",
              " 'having',\n",
              " 'that',\n",
              " 'gene',\n",
              " 'or',\n",
              " 'by',\n",
              " 'chance',\n",
              " '.',\n",
              " 'They',\n",
              " 'do',\n",
              " \"n't\",\n",
              " 'disappear',\n",
              " ',',\n",
              " \"''\",\n",
              " 'he',\n",
              " 'told',\n",
              " 'BBC',\n",
              " 'News',\n",
              " 'Online',\n",
              " '.',\n",
              " '``',\n",
              " 'The',\n",
              " 'only',\n",
              " 'reason',\n",
              " 'blondes',\n",
              " 'would',\n",
              " 'disappear',\n",
              " 'is',\n",
              " 'if',\n",
              " 'having',\n",
              " 'the',\n",
              " 'gene',\n",
              " 'was',\n",
              " 'a',\n",
              " 'disadvantage',\n",
              " 'and',\n",
              " 'I',\n",
              " 'do',\n",
              " 'not',\n",
              " 'think',\n",
              " 'that',\n",
              " 'is',\n",
              " 'the',\n",
              " 'case',\n",
              " '.',\n",
              " '``',\n",
              " 'The',\n",
              " 'frequency',\n",
              " 'of',\n",
              " 'blondes',\n",
              " 'may',\n",
              " 'drop',\n",
              " 'but',\n",
              " 'they',\n",
              " 'wo',\n",
              " \"n't\",\n",
              " 'disappear',\n",
              " '.',\n",
              " \"''\",\n",
              " 'See',\n",
              " 'also',\n",
              " ':',\n",
              " '28',\n",
              " 'Mar',\n",
              " '01',\n",
              " '|',\n",
              " 'Education',\n",
              " 'What',\n",
              " 'is',\n",
              " 'it',\n",
              " 'about',\n",
              " 'blondes',\n",
              " '?',\n",
              " '09',\n",
              " 'Apr',\n",
              " '99',\n",
              " '|',\n",
              " 'Health',\n",
              " 'Platinum',\n",
              " 'blondes',\n",
              " 'are',\n",
              " 'labelled',\n",
              " 'as',\n",
              " 'dumb',\n",
              " '17',\n",
              " 'Apr',\n",
              " '02',\n",
              " '|',\n",
              " 'Health',\n",
              " 'Hair',\n",
              " 'dye',\n",
              " 'cancer',\n",
              " 'alert',\n",
              " 'Internet',\n",
              " 'links',\n",
              " ':',\n",
              " 'University',\n",
              " 'of',\n",
              " 'Edinburgh',\n",
              " 'The',\n",
              " 'BBC',\n",
              " 'is',\n",
              " 'not',\n",
              " 'responsible',\n",
              " 'for',\n",
              " 'the',\n",
              " 'content',\n",
              " 'of',\n",
              " 'external',\n",
              " 'internet',\n",
              " 'sites',\n",
              " 'Top',\n",
              " 'Health',\n",
              " 'stories',\n",
              " 'now',\n",
              " ':',\n",
              " 'Heart',\n",
              " 'risk',\n",
              " 'link',\n",
              " 'to',\n",
              " 'big',\n",
              " 'families',\n",
              " 'Back',\n",
              " 'pain',\n",
              " 'drug',\n",
              " \"'may\",\n",
              " 'aid',\n",
              " \"diabetics'\",\n",
              " 'Congo',\n",
              " 'Ebola',\n",
              " 'outbreak',\n",
              " 'confirmed',\n",
              " 'Vegetables',\n",
              " 'ward',\n",
              " 'off',\n",
              " \"Alzheimer's\",\n",
              " 'Polio',\n",
              " 'campaign',\n",
              " 'launched',\n",
              " 'in',\n",
              " 'Iraq',\n",
              " 'Gene',\n",
              " 'defect',\n",
              " 'explains',\n",
              " 'high',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'Botox',\n",
              " \"'may\",\n",
              " 'cause',\n",
              " 'new',\n",
              " \"wrinkles'\",\n",
              " 'Alien',\n",
              " \"'abductees\",\n",
              " \"'\",\n",
              " 'show',\n",
              " 'real',\n",
              " 'symptoms',\n",
              " 'Links',\n",
              " 'to',\n",
              " 'more',\n",
              " 'Health',\n",
              " 'stories',\n",
              " 'are',\n",
              " 'at',\n",
              " 'the',\n",
              " 'foot',\n",
              " 'of',\n",
              " 'the',\n",
              " 'page',\n",
              " '.',\n",
              " 'E-mail',\n",
              " 'this',\n",
              " 'story',\n",
              " 'to',\n",
              " 'a',\n",
              " 'friend',\n",
              " 'Links',\n",
              " 'to',\n",
              " 'more',\n",
              " 'Health',\n",
              " 'stories',\n",
              " 'In',\n",
              " 'This',\n",
              " 'Section',\n",
              " 'Heart',\n",
              " 'risk',\n",
              " 'link',\n",
              " 'to',\n",
              " 'big',\n",
              " 'families',\n",
              " 'Back',\n",
              " 'pain',\n",
              " 'drug',\n",
              " \"'may\",\n",
              " 'aid',\n",
              " \"diabetics'\",\n",
              " 'Congo',\n",
              " 'Ebola',\n",
              " 'outbreak',\n",
              " 'confirmed',\n",
              " 'Vegetables',\n",
              " 'ward',\n",
              " 'off',\n",
              " \"Alzheimer's\",\n",
              " 'Polio',\n",
              " 'campaign',\n",
              " 'launched',\n",
              " 'in',\n",
              " 'Iraq',\n",
              " 'Gene',\n",
              " 'defect',\n",
              " 'explains',\n",
              " 'high',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'Botox',\n",
              " \"'may\",\n",
              " 'cause',\n",
              " 'new',\n",
              " \"wrinkles'\",\n",
              " 'Alien',\n",
              " \"'abductees\",\n",
              " \"'\",\n",
              " 'show',\n",
              " 'real',\n",
              " 'symptoms',\n",
              " 'How',\n",
              " 'sperm',\n",
              " 'wriggle',\n",
              " 'Bollywood',\n",
              " 'told',\n",
              " 'to',\n",
              " 'stub',\n",
              " 'it',\n",
              " 'out',\n",
              " 'Fears',\n",
              " 'over',\n",
              " 'tuna',\n",
              " 'health',\n",
              " 'risk',\n",
              " 'to',\n",
              " 'babies',\n",
              " 'Public',\n",
              " 'can',\n",
              " 'be',\n",
              " 'taught',\n",
              " 'to',\n",
              " 'spot',\n",
              " 'strokes',\n",
              " '^^',\n",
              " 'Back',\n",
              " 'to',\n",
              " 'top',\n",
              " 'News',\n",
              " 'Front',\n",
              " 'Page',\n",
              " '|',\n",
              " 'Africa',\n",
              " '|',\n",
              " 'Americas',\n",
              " '|',\n",
              " 'Asia-Pacific',\n",
              " '|',\n",
              " 'Europe',\n",
              " '|',\n",
              " 'Middle',\n",
              " 'East',\n",
              " '|',\n",
              " 'South',\n",
              " 'Asia',\n",
              " '|',\n",
              " 'UK',\n",
              " '|',\n",
              " 'Business',\n",
              " '|',\n",
              " 'Entertainment',\n",
              " '|',\n",
              " 'Science/Nature',\n",
              " '|',\n",
              " 'Technology',\n",
              " '|',\n",
              " 'Health',\n",
              " '|',\n",
              " 'Talking',\n",
              " 'Point',\n",
              " '|',\n",
              " 'Country',\n",
              " 'Profiles',\n",
              " '|',\n",
              " 'In',\n",
              " 'Depth',\n",
              " '|',\n",
              " 'Programmes',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " 'To',\n",
              " 'BBC',\n",
              " 'Sport',\n",
              " '>',\n",
              " '>',\n",
              " '|',\n",
              " 'To',\n",
              " 'BBC',\n",
              " 'Weather',\n",
              " '>',\n",
              " '>',\n",
              " '|',\n",
              " 'To',\n",
              " 'BBC',\n",
              " 'World',\n",
              " 'Service',\n",
              " '>',\n",
              " '>',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '--',\n",
              " '©',\n",
              " 'MMIII',\n",
              " '|',\n",
              " 'News',\n",
              " 'Sources',\n",
              " '|',\n",
              " 'Privacy',\n",
              " '<',\n",
              " '!',\n",
              " '--',\n",
              " 'var',\n",
              " 'pCid=',\n",
              " \"''\",\n",
              " 'uk_bbc_0',\n",
              " \"''\",\n",
              " ';',\n",
              " 'var',\n",
              " 'w0=1',\n",
              " ';',\n",
              " 'var',\n",
              " 'refR=escape',\n",
              " '(',\n",
              " 'document.referrer',\n",
              " ')',\n",
              " ';',\n",
              " 'if',\n",
              " '(',\n",
              " 'refR.length',\n",
              " '>',\n",
              " '=252',\n",
              " ')',\n",
              " 'refR=refR.substring',\n",
              " '(',\n",
              " '0,252',\n",
              " ')',\n",
              " '+',\n",
              " \"''\",\n",
              " '...',\n",
              " \"''\",\n",
              " ';',\n",
              " '//',\n",
              " '--',\n",
              " '>',\n",
              " '<',\n",
              " '!',\n",
              " '--',\n",
              " 'var',\n",
              " 'w0=0',\n",
              " ';',\n",
              " '//',\n",
              " '--',\n",
              " '>',\n",
              " '<',\n",
              " '!',\n",
              " '--',\n",
              " 'if',\n",
              " '(',\n",
              " 'w0',\n",
              " ')',\n",
              " '{',\n",
              " 'var',\n",
              " 'imgN=',\n",
              " \"'\",\n",
              " '<',\n",
              " 'img',\n",
              " 'src=',\n",
              " \"''\",\n",
              " 'http',\n",
              " ':',\n",
              " '//server-uk.imrworldwide.com/cgi-bin/count',\n",
              " '?',\n",
              " \"ref='+\",\n",
              " 'refR+',\n",
              " \"'\",\n",
              " '&',\n",
              " \"cid='+pCid+\",\n",
              " \"'\",\n",
              " \"''\",\n",
              " 'width=1',\n",
              " 'height=1',\n",
              " '>',\n",
              " \"'\",\n",
              " ';',\n",
              " 'if',\n",
              " '(',\n",
              " 'navigator.userAgent.indexOf',\n",
              " '(',\n",
              " \"'Mac\",\n",
              " \"'\",\n",
              " ')',\n",
              " '!',\n",
              " '=-1',\n",
              " ')',\n",
              " '{',\n",
              " 'document.write',\n",
              " '(',\n",
              " 'imgN',\n",
              " ')',\n",
              " ';',\n",
              " '}',\n",
              " 'else',\n",
              " '{',\n",
              " 'document.write',\n",
              " '(',\n",
              " \"'\",\n",
              " '<',\n",
              " 'applet',\n",
              " 'code=',\n",
              " \"''\",\n",
              " 'Measure.class',\n",
              " \"''\",\n",
              " \"'+\",\n",
              " \"'codebase=\",\n",
              " \"''\",\n",
              " 'http',\n",
              " ':',\n",
              " '//server-uk.imrworldwide.com/',\n",
              " \"''\",\n",
              " \"'+'width=1\",\n",
              " 'height=2',\n",
              " '>',\n",
              " \"'+\",\n",
              " \"'\",\n",
              " '<',\n",
              " 'param',\n",
              " 'name=',\n",
              " \"''\",\n",
              " 'ref',\n",
              " \"''\",\n",
              " 'value=',\n",
              " \"''\",\n",
              " \"'+refR+\",\n",
              " \"'\",\n",
              " \"''\",\n",
              " '>',\n",
              " \"'+\",\n",
              " \"'\",\n",
              " '<',\n",
              " 'param',\n",
              " 'name=',\n",
              " \"''\",\n",
              " 'cid',\n",
              " \"''\",\n",
              " 'value=',\n",
              " \"''\",\n",
              " \"'+pCid+\",\n",
              " \"'\",\n",
              " \"''\",\n",
              " '>',\n",
              " '<',\n",
              " 'textflow',\n",
              " '>',\n",
              " \"'+imgN+\",\n",
              " \"'\",\n",
              " '<',\n",
              " '/textflow',\n",
              " '>',\n",
              " '<',\n",
              " '/applet',\n",
              " '>',\n",
              " \"'\",\n",
              " ')',\n",
              " ';',\n",
              " '}',\n",
              " '}',\n",
              " 'document.write',\n",
              " '(',\n",
              " '``',\n",
              " '<',\n",
              " 'COMMENT',\n",
              " '>',\n",
              " \"''\",\n",
              " ')',\n",
              " ';',\n",
              " '//',\n",
              " '--',\n",
              " '>',\n",
              " 'var',\n",
              " 'si',\n",
              " '=',\n",
              " 'document.location+',\n",
              " \"''\",\n",
              " \"''\",\n",
              " ';',\n",
              " 'var',\n",
              " 'tsi',\n",
              " '=',\n",
              " 'si.replace',\n",
              " '(',\n",
              " '``',\n",
              " '.stm',\n",
              " \"''\",\n",
              " ',',\n",
              " \"''\",\n",
              " \"''\",\n",
              " ')',\n",
              " '.substr',\n",
              " '(',\n",
              " 'si.length-11',\n",
              " ',',\n",
              " 'si.length',\n",
              " ')',\n",
              " ';',\n",
              " 'if',\n",
              " '(',\n",
              " '!',\n",
              " 'tsi.match',\n",
              " '(',\n",
              " '/\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d/',\n",
              " ')',\n",
              " ')',\n",
              " '{',\n",
              " 'tsi',\n",
              " '=',\n",
              " '0',\n",
              " ';',\n",
              " '}',\n",
              " 'document.write',\n",
              " '(',\n",
              " \"'\",\n",
              " '<',\n",
              " 'img',\n",
              " 'src=',\n",
              " \"''\",\n",
              " 'http',\n",
              " ':',\n",
              " '//stats.bbc.co.uk/o.gif',\n",
              " '?',\n",
              " '~RS~s~RS~News~RS~t~RS~HighWeb_Legacy~RS~i~RS~',\n",
              " \"'\",\n",
              " '+',\n",
              " 'tsi',\n",
              " '+',\n",
              " \"'~RS~p~RS~0~RS~u~RS~/2/hi/health/2284783.stm~RS~r~RS~\",\n",
              " '(',\n",
              " 'none',\n",
              " ')',\n",
              " '~RS~a~RS~International~RS~q~RS~~RS~z~RS~07~RS~',\n",
              " \"''\",\n",
              " '>',\n",
              " \"'\",\n",
              " ')',\n",
              " ';']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoZ3KNCRKi_O",
        "outputId": "ac4ccf16-3d98-4f9b-dc1a-56ca0c320533"
      },
      "source": [
        "tokens_bs = tokens_bs[110:390]\n",
        "text = nltk.Text(tokens_bs)\n",
        "text.concordance('gene')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 5 of 5 matches:\n",
            "hey say too few people now carry the gene for blondes to last beyond the next \n",
            "blonde hair is caused by a recessive gene . In order for a child to have blond\n",
            " have blonde hair , it must have the gene on both sides of the family in the g\n",
            "ere is a disadvantage of having that gene or by chance . They do n't disappear\n",
            "des would disappear is if having the gene was a disadvantage and I do not thin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCfj8CqqLIAw"
      },
      "source": [
        "## 2) PDF 크롤링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZdZ8GmkLd96",
        "outputId": "61a22cd7-1fec-4129-fc12-6f4596046d7a"
      },
      "source": [
        "!pip install PyPDF2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 3.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyPDF2\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61101 sha256=c6f2deb83567726da953ca57450880a5612472d32f266e8346c8074ee7db0b93\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1a/24/648467ade3a77ed20f35cfd2badd32134e96dd25ca811e64b3\n",
            "Successfully built PyPDF2\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-1.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlMOWjvRLKot"
      },
      "source": [
        "from PyPDF2 import PdfFileReader\n",
        "import os\n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISuLPZTsLoaz"
      },
      "source": [
        "def text_extrator(path):\n",
        "  with open(path, 'rb') as f:\n",
        "    pdf = PdfFileReader(f)\n",
        "\n",
        "    # 첫번째 페이지 가져오기\n",
        "    page = pdf.getPage(1)\n",
        "    print(page)\n",
        "    print('Page type: {}'.format(str(type(page))))\n",
        "\n",
        "    text = page.extractText()\n",
        "    raw_pdf = text\n",
        "    print(len(text), type(raw))\n",
        "\n",
        "    tokens_pdf = nltk_word_tokenize(raw_pdf)\n",
        "    print(type(tokens_pdf), len(tokens_pdf))\n",
        "\n",
        "    print('text length is:', len(text))\n",
        "    print(raw_pdf)\n",
        "    print(raw_pdf.find('Method'))\n",
        "    print(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs3592rwMYuN"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  path = 'US9152209.pdf'\n",
        "  text_extrator(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRNTYbQGLLM2"
      },
      "source": [
        "## 3) Word file 크롤링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1Bo6VVYLNZM",
        "outputId": "fa7f2677-5120-4baa-f9f0-cb2d81f5f5e0"
      },
      "source": [
        "!pip install python-docx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx) (4.2.6)\n",
            "Building wheels for collected packages: python-docx\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184508 sha256=31ac32edbdcfe9fdf9fc1d5f602d65d412daec8ea3acbdd50bb042c876bf6f8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "Successfully built python-docx\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-0.8.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wBkaNguNUWs"
      },
      "source": [
        "import docx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4YCDCMpNWdf"
      },
      "source": [
        "doc = docx.Document('Synset.docx')\n",
        "\n",
        "for i in doc.paragraphs:\n",
        "  print(i.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmUgdCwRNdaE"
      },
      "source": [
        "doc = docx.Document()\n",
        "\n",
        "doc.add_heading('Header 0', 0)\n",
        "doc.add_heading('Header 1', 1)\n",
        "doc.add_heading('Header 2', 2)\n",
        "doc.add_heading('Header 3', 3)\n",
        "doc.add_heading('Header 4', 4)\n",
        "doc.save('headings.docx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpSH3-kvN1aM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saj_GsfmQWjp"
      },
      "source": [
        "# 3. Regular Expressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyVfmUxkQYt0"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz8KeZJYQZbt",
        "outputId": "e55526fd-d100-44b7-dd83-46674766bd16"
      },
      "source": [
        "[w for w in tokens_bs if re.search('ed$', w)] #('ed')로 끝나는 글자"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['endangered', 'caused', 'Dyed', 'so-called']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruplgRA3QiKl",
        "outputId": "52736170-657d-424a-d7ad-28bee398e98f"
      },
      "source": [
        "[w for w in tokens_bs if re.search('^.j..t.$', w)] # 중간에 j가 나오고 두 글자 나오고 t 나오는 글자"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM-8VBC5Q4bk",
        "outputId": "270859cb-0704-442d-8874-24e3c0399885"
      },
      "source": [
        "s = 'Oyfn pripetchik A AB ABc'.split()\n",
        "[w for w in s if re.search('[^A-Z]', w)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Oyfn', 'pripetchik', 'ABc']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APzjeNgZRHyK",
        "outputId": "b0a8beb2-f235-44c1-f6e6-cda6bc8b5a36"
      },
      "source": [
        "s = \"I am the other person who knows the theology and I'm typing just random words in order to check 'the' sentence\"\n",
        "[w for w in s if re.search('[^a-zA-Z][tT]he[^a-zA-Z]', w)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FYGNuSIRoul"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}